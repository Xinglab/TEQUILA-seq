# Data analysis of TEQUILA-seq

## About

This is a workflow for analyzing the data generated by TEQUILA-seq (Target Enrichment and Quantification Utilizing Isothermally Linear-Amplified probes in conjunction with long-read Sequencing). The workflow consists of two parts: 1) Identification and quantification of isoform using ESPRESSO tool (this pipeline has been wrapped up as a snakemake workflow) and 2) downstream data analysis and visualization. 


## Table of contents

* [Data process](#data-process)
  + [Install](#install)
  + [Usage](#usage)
  + [Configuration](#configuration)
* [Data analysis and visualization](#data-analysis-and-visualization)


## Data process

Since we only focus on the identification and quantification of isoforms based on long-read RNA-seq data, we just need to use the old version of [long-read-pipeline](https://github.com/Xinglab/long-read-pipeline/) for simplicity. (The link is directed to the most recent version, and this repository is the old one). <br/><br/>
And it should be noted that this pipeline will detect isoforms based on all samples and replicates in [snakemake_config.yaml](snakemake_config.yaml), which is great if we want to do the discovery work. But in the TEQUILA-seq project, the main purpose is to check the robustness and reproducibility of the technique, we need to perform ESPRESSO on each replicates, separately. <br/>

[Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/linux.html) must be installed first. Then the detailed steps are as follows:

#### Install

1. Enter `TEQUILA-seq` folder.
2. Modify `CONDA_ENV_PREFIX` paths in [set_env_vars.sh](set_env_vars.sh)
3. Install other dependencies using conda: `./install`.
4. Manually install following packages:
    + argparse: `conda install -c conda-forge configargparse`
5. Download reference genome sequence and put it into the 'references' folder: https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_34/GRCh37_mapping/gencode.v34lift37.annotation.gtf.gz
6. Modify some absolute file paths in [snakemake_config.yaml](snakemake_config.yaml).
    + In this project, we mainly have three sample groups: `brain sample + SIRVset4`, `SH-SY5Y cell + SIRVset4` and 'BRCA cell lines'.
    + Configure files of 'Brain' and 'SH-SY5Y' samples are pre-defined in the `Config_for_each_system`. When performing the analysis, the desired `snakemake_config.yaml` should be copied into main folder.
    + The `visualization_path` and `conda_wrapper` of `snakemake_config.yaml` should be modified accordingly.

#### Usage

Note: all commands should be run under the conda environment: 
1. Run the workflow with `sbatch --time=7-0:0:0 ./run` (Base-calling, alignment and isoform identification based on all samples)
2. When the alignment is done, we need to generate bash files for each sample separately with `python generate_ESPRESSO_separately.py --sample [sample1 sample2...] --ref [ref]` (Isoform identification based on each sample/replicate). 
3. Submit generated bash file for isoform identification.   e.g. `sbatch sbatch_ESPRESSO_RBP_SDA_8h_1.sh`
4. When ESPRESSO job is done for all samples, run `sh ./merge_exp_matrix_and_gtf.sh` to merge results for individual samples.

#### Configuration

[snakemake_config.yaml](snakemake_config.yaml)
* `long_read_samples`
  + each sample has its own entry which defines the `sample_name`
  + if starting from fast5 files then under `sample_name` set: `fast5_dir` and `guppy_config`: e.g.
```
    samples:
      RNA_sample_1:
        - guppy_config: 'dna_r9.4.1_450bps_fast.cfg'
          fast5_dir: '~/fast5/'
```
  + if starting from a fastq file then under `sample_name` set: `fastq`: e.g.
```
    samples:
      RNA_sample_1:
        - fastq: '~/combined.fastq'
```
* `guppy_bin_path: '/path/to/guppy/bin/'` (only needed if starting from fast5 files)
* Specify the reference files to use:
  + Either manually put each file in `references/` or provide a url to download the (potentially gzipped) file:
  + `gtf_name: 'file_name.gtf'`
  + `gff3_name: 'file_name.gff3'`
  + `fasta_name: 'file_name.fasta'`
* `conda_wrapper:`: based on current folder
* `espresso_path:`: based on current folder
```
reference_files:
  file_name.gtf.gz:
    url: 'protocol://url/for/file_name.gtf.gz'
```


## Data analysis and visualization

### 10 Brain genes panel
Note: all commands should be run under the conda environment: 
1. Manually install following packages:
  + R: `conda config --add channels conda-forge`
  + `conda config --set channel_priority strict`
  + `conda create -n r_plot r-essentials r-base=4.0.5`
  + `conda activate r_plot`
  + ggplot2: `conda install -c r r-ggplot2`
  + tidyverse: `conda install -c r r-tidyverse`
  + ggplotify: `conda install -c conda-forge r-ggplotify`
  + numpy for python: `conda install -c anaconda numpy`
2. Copy 'statistics' folder into 'espresso_out_combine' folder: `cp -r ./statistics ./espresso_out_combine`
3. Enter the statistics folder: `cd ./espresso_out_combined/statistics`
4. Run statistics analysis, and we can get the summarized result for each sample/replicate, such as total reads, number of reads mapped to target genes and etc. :  `sh statistics_pipeline.sh`
5. Enter `reads_count` folder, and obtain the number of reads that mapped to the top 30 genes in each sample:
  + `python Target_gene_expression_top_rank.py`
  + `sbatch sbatch_count_reads_NonCapture_Ctrl.sh`
  + `sbatch sbatch_count_reads_Target_IDT.sh`
  + `sbatch sbatch_count_reads_Target_TEQUILA.sh`
6. Go back to the `statistics` folder, generate figures: `sh Plot_figure.sh`



### SIRV genes panel
Note: all commands should be run under the conda environment: 
1. Manually install following packages:
  + `conda activate r_plot`
  + scales: `conda install -c r r-scales`
  + forcats: `conda install -c conda-forge r-forcats`
2. Copy 'statistics' folder into 'espresso_out_combine' folder: `cp -r ./statistics_SIRVset4/statistics ./espresso_out_combine` (under SIRV dataset folder)
3. Enter the statistics folder: `cd ./espresso_out_combined/statistics`
4. Generate figures: `sh Plot_figure.sh`
5. Run statistics analysis, and we can get the summarized result for each sample/replicate, such as total reads, number of reads mapped to target genes and etc. :  `sh statistics_pipeline.sh`
